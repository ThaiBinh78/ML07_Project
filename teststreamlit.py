# app_motor_price.py
import streamlit as st
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import io
import os
import traceback

# ----------------------
# CONFIG (Streamlit Cloud compatible)
# ----------------------
MODEL_PATH = "rf_pipeline.pkl"
ISO_PATH = "isolation_forest.pkl"
SAMPLE_PATH = "sample_data.csv"
FI_CSV = "feature_importances.csv"

PENDING_PATH = Path("pending_listings.csv")
LOG_PATH = Path("prediction_logs.csv")

CURRENT_YEAR = datetime.now().year

st.set_page_config(page_title="D·ª± ƒëo√°n gi√° - Xe m√°y c≈©", layout="wide")

# ----------------------
# Helpers
# ----------------------
@st.cache_resource
def load_models_and_sample(rf_path, iso_path, sample_path):
    """
    Load model, iso, sample. Normalize sample column names so downstream code is stable.
    """
    # load model & iso
    model = joblib.load(rf_path)
    iso = joblib.load(iso_path)

    # load sample
    sample = pd.read_csv(sample_path)

    # Normalize column names (handle variants)
    sample = sample.rename(columns=lambda x: x.strip())

    # unify price column to 'Gia_trieu' numeric (tri·ªáu)
    if 'Gia_trieu' not in sample.columns and 'Gi√°' in sample.columns:
        # assume 'Gi√°' maybe in million or exact? user used Gia_trieu in training
        # try to coerce to numeric
        sample['Gia_trieu'] = pd.to_numeric(sample['Gi√°'], errors='coerce')
    else:
        if 'Gia_trieu' in sample.columns:
            sample['Gia_trieu'] = pd.to_numeric(sample['Gia_trieu'], errors='coerce')

    # ensure Kho·∫£ng gi√° min/max are numeric if exist
    for col in ["Kho·∫£ng gi√° min", "Kho·∫£ng gi√° max", "Gi√°"]:
        if col in sample.columns:
            sample[col] = pd.to_numeric(sample[col], errors='coerce')

    return model, iso, sample

def ensure_cols_for_upload(df):
    required = [
        "Th∆∞∆°ng_hi·ªáu","D√≤ng_xe","Lo·∫°i_xe","Dung_t√≠ch_xe",
        "NƒÉm_ƒëƒÉng_k√Ω","S·ªë_Km_ƒë√£_ƒëi","Gi√°","Kho·∫£ng_gi√°_min","Kho·∫£ng_gi√°_max",
        "Ti√™u_ƒë·ªÅ","M√¥_t·∫£_chi_ti·∫øt","ƒê·ªãa_ch·ªâ"
    ]
    missing = [c for c in required if c not in df.columns]
    return missing

def add_pending(entry: dict):
    # ensure pending file exists or create
    if PENDING_PATH.exists():
        df = pd.read_csv(PENDING_PATH)
    else:
        df = pd.DataFrame()
    entry_id = int(datetime.utcnow().timestamp() * 1000)
    entry["id"] = entry_id
    df = pd.concat([pd.DataFrame([entry]), df], ignore_index=True, sort=False)
    df.to_csv(PENDING_PATH, index=False)
    return entry_id

def log_prediction(record: dict):
    if LOG_PATH.exists():
        logs = pd.read_csv(LOG_PATH)
    else:
        logs = pd.DataFrame()
    logs = pd.concat([pd.DataFrame([record]), logs], ignore_index=True, sort=False)
    logs.to_csv(LOG_PATH, index=False)

def human_currency(x):
    # input x is in the same units as training (likely 'Gia_trieu' = million VND)
    try:
        v = float(x)
        # present nice format: use millions with commas
        return f"{v:,.2f} Tri·ªáu"
    except:
        return x

def compute_anomaly_score(sample_df, brand, actual_price, pred, iso, X_trans_for_iso):
    """
    Compute 4 components:
    1) residual z (brand IQR or global std fallback)
    2) min/max violation
    3) outside [P10,P90]
    4) isolation forest raw score -> normalized
    Return final_score (0-100) and dict of details.
    - actual_price and pred are assumed same unit (Tri·ªáu)
    - X_trans_for_iso: 1-D or 2-D vector that already includes residual column appended
    """
    try:
        resid = (actual_price - pred) if (actual_price is not None and not pd.isna(actual_price)) else (0.0 - pred)
    except Exception:
        resid = 0.0 - pred

    # ensure sample brand selection works for different column name variants
    if 'Th∆∞∆°ng hi·ªáu' in sample_df.columns:
        sample_brand = sample_df[sample_df['Th∆∞∆°ng hi·ªáu'] == brand].copy()
    elif 'Th∆∞∆°ng_hi·ªáu' in sample_df.columns:
        sample_brand = sample_df[sample_df['Th∆∞∆°ng_hi·ªáu'] == brand].copy()
    else:
        sample_brand = pd.DataFrame()

    # resid_z
    if len(sample_brand) >= 10 and 'Gia_trieu' in sample_brand.columns:
        iqr = (sample_brand['Gia_trieu'].quantile(0.75) - sample_brand['Gia_trieu'].quantile(0.25)) or 1.0
        resid_z = abs(resid) / max(iqr, 1e-6)
    else:
        global_std = sample_df['Gia_trieu'].std() if 'Gia_trieu' in sample_df.columns else 1.0
        resid_z = abs(resid) / max(1.0, global_std)

    # min/max
    min_price = sample_brand['Kho·∫£ng gi√° min'].min() if ('Kho·∫£ng gi√° min' in sample_brand.columns and len(sample_brand)>0) else np.nan
    max_price = sample_brand['Kho·∫£ng gi√° max'].max() if ('Kho·∫£ng gi√° max' in sample_brand.columns and len(sample_brand)>0) else np.nan
    violate_minmax = int((not pd.isna(min_price) and (actual_price < min_price)) or (not pd.isna(max_price) and (actual_price > max_price)))

    # p10/p90
    p10 = sample_brand['Gia_trieu'].quantile(0.10) if (len(sample_brand)>0 and 'Gia_trieu' in sample_brand.columns) else np.nan
    p90 = sample_brand['Gia_trieu'].quantile(0.90) if (len(sample_brand)>0 and 'Gia_trieu' in sample_brand.columns) else np.nan
    outside_p10p90 = int((not pd.isna(p10) and actual_price < p10) or (not pd.isna(p90) and actual_price > p90))

    # isolation: X_trans_for_iso must be 1D or 2D array including residual column as last column
    iso_vec = X_trans_for_iso
    if hasattr(iso_vec, "toarray"):
        iso_vec = iso_vec.toarray()
    iso_vec = np.asarray(iso_vec)
    # shape normalize
    if iso_vec.ndim == 1:
        iso_vec = iso_vec.reshape(1, -1)

    try:
        iso_score_raw = - iso.decision_function(iso_vec)[0]
        iso_flag = int(iso.predict(iso_vec)[0] == -1)
    except Exception:
        iso_score_raw = 0.0
        iso_flag = 0

    # combine weights
    w1, w2, w3, w4 = 0.4, 0.2, 0.2, 0.2
    score1 = min(1.0, resid_z / 3.0) * 100.0
    score2 = violate_minmax * 100.0
    score3 = outside_p10p90 * 100.0
    score4 = min(1.0, iso_score_raw / 0.5) * 100.0
    final_score = w1*score1 + w2*score2 + w3*score3 + w4*score4

    return final_score, {
        "resid": float(resid),
        "resid_z": float(resid_z),
        "violate_minmax": int(violate_minmax),
        "outside_p10p90": int(outside_p10p90),
        "iso_flag": int(iso_flag),
        "iso_score_raw": float(iso_score_raw),
        "score_components": {"score1": score1, "score2": score2, "score3": score3, "score4": score4}
    }

# ----------------------
# Load models & sample (safe)
# ----------------------
try:
    if not Path(MODEL_PATH).exists() or not Path(ISO_PATH).exists() or not Path(SAMPLE_PATH).exists():
        missing = [p for p in [MODEL_PATH, ISO_PATH, SAMPLE_PATH] if not Path(p).exists()]
        raise FileNotFoundError(f"Missing files: {missing}. Make sure these files are in the same folder as this app.")
    model, iso, sample_df = load_models_and_sample(MODEL_PATH, ISO_PATH, SAMPLE_PATH)
except Exception as e:
    st.error("Kh√¥ng th·ªÉ load model/sample. Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n & file c√≥ trong repo hay kh√¥ng.")
    st.write(str(e))
    # print traceback to logs for debug (not shown to users)
    st.write(traceback.format_exc())
    st.stop()

# ----------------------
# Sidebar menu (single page app with sidebar)
# ----------------------
st.sidebar.title("Menu")
# show banner only if exists
if Path("xe_may_cu.jpg").exists():
    st.sidebar.image("xe_may_cu.jpg", use_column_width=True)
page = st.sidebar.radio("Ch·ªçn m·ª•c", ["Business Problem", "Prediction", "Anomaly Check", "Admin Dashboard", "Logs", "Evaluation & Report", "Team Info"])

# ----------------------
# Business Problem (static)
# ----------------------
def render_business_problem():
    st.title("Business Problem")
    st.markdown("""
- **M·ª•c ti√™u:** D·ª± ƒëo√°n gi√° b√°n h·ª£p l√Ω cho xe m√°y c≈© (ng∆∞·ªùi mua/ ng∆∞·ªùi b√°n) v√† ph√°t hi·ªán c√°c tin ƒëƒÉng c√≥ gi√° b·∫•t th∆∞·ªùng.
- **Input:** Th∆∞∆°ng hi·ªáu, D√≤ng xe, NƒÉm ƒëƒÉng k√Ω, S·ªë Km, Lo·∫°i xe, Dung t√≠ch, Xu·∫•t x·ª©, (Gi√° th·ª±c - t√πy ch·ªçn).
- **Output:** Gi√° d·ª± ƒëo√°n (Tri·ªáu VNƒê) + Anomaly Score (0-100) + K·∫øt lu·∫≠n (Gi√° th·∫•p b·∫•t th∆∞·ªùng / Gi√° cao b·∫•t th∆∞·ªùng / B√¨nh th∆∞·ªùng).
- **Ph∆∞∆°ng ph√°p:** RandomForest cho regression; IsolationForest + th·ªëng k√™ cho anomaly detection.
    """)
if page == "Business Problem":
    render_business_problem()

# ----------------------
# PREDICTION PAGE (single tab with two options)
# ----------------------
if page == "Prediction":
    st.title(" D·ª± ƒëo√°n gi√° & Ki·ªÉm tra b·∫•t th∆∞·ªùng ‚Äî Xe m√°y c≈©")
    st.markdown("Ch·ªçn c√°ch nh·∫≠p: Nh·∫≠p tay ho·∫∑c Upload file CSV/XLSX (12 c·ªôt chu·∫©n).")

    mode = st.radio("Ch·ªçn ch·∫ø ƒë·ªô", ["Nh·∫≠p tay", "Upload file (CSV/XLSX)"], index=0)

    if mode == "Nh·∫≠p tay":
        st.subheader("Nh·∫≠p chi ti·∫øt tin ƒëƒÉng")
        with st.form("form_single", clear_on_submit=False):
            col1, col2 = st.columns([2,1])
            with col1:
                title = st.text_input("Ti√™u ƒë·ªÅ tin ƒëƒÉng", value="B√°n SH Mode 125 ch√≠nh ch·ªß")
                description = st.text_area("M√¥ t·∫£ chi ti·∫øt", value="Xe ƒë·∫πp, bao test, bi·ªÉn s·ªë TP, gi√° c√≥ th∆∞∆°ng l∆∞·ª£ng.")
                address = st.text_input("ƒê·ªãa ch·ªâ", value="Qu·∫≠n 1, TP. H·ªì Ch√≠ Minh")
                # safe selectbox with fallback
                brands = sample_df['Th∆∞∆°ng hi·ªáu'].dropna().unique().tolist() if 'Th∆∞∆°ng hi·ªáu' in sample_df.columns else []
                brands = sorted(brands) if brands else ['unknown']
                brand = st.selectbox("Th∆∞∆°ng hi·ªáu", options=brands)
                model_name = st.text_input("D√≤ng xe", value="")
                loai_values = sample_df['Lo·∫°i xe'].dropna().unique().tolist() if 'Lo·∫°i xe' in sample_df.columns else []
                loai = st.selectbox("Lo·∫°i xe", options=sorted(loai_values) if loai_values else ['unknown'])
            with col2:
                dungtich = st.text_input("Dung t√≠ch xe (v√≠ d·ª• '100 - 175 cc' ho·∫∑c '125')", value="125")
                age = st.slider("Tu·ªïi xe (nƒÉm)", 0, 50, 3)
                year_reg = int(CURRENT_YEAR - age)
                st.write(f"NƒÉm ƒëƒÉng k√Ω (t∆∞∆°ng ·ª©ng): {year_reg}")
                km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=500000, value=20000, step=1000)
                price_input = st.number_input("Gi√° th·ª±c (Tri·ªáu VNƒê) ‚Äî n·∫øu mu·ªën (t√πy ch·ªçn)", min_value=0.0, value=0.0, step=0.1, format="%.2f")
                price_min = st.number_input("Kho·∫£ng_gi√°_min (Tri·ªáu) ‚Äî c√≥ th·ªÉ b·ªè tr·ªëng", min_value=0.0, value=0.0, step=0.1, format="%.2f")
                price_max = st.number_input("Kho·∫£ng_gi√°_max (Tri·ªáu) ‚Äî c√≥ th·ªÉ b·ªè tr·ªëng", min_value=0.0, value=0.0, step=0.1, format="%.2f")

            publish = st.checkbox("L∆∞u ƒë·ªÉ Admin duy·ªát (ƒëƒÉng b√°n)")
            submitted = st.form_submit_button("Predict & Check Anomaly")

        if submitted:
            # Build input df with correct training column names:
            input_df = pd.DataFrame([{
                "Th∆∞∆°ng hi·ªáu": brand,
                "D√≤ng xe": model_name if model_name.strip()!="" else "unknown",
                "NƒÉm ƒëƒÉng k√Ω": year_reg,
                "S·ªë Km ƒë√£ ƒëi": km,
                "T√¨nh tr·∫°ng": "ƒê√£ s·ª≠ d·ª•ng",
                "Lo·∫°i xe": loai,
                "Dung t√≠ch xe": dungtich,
                "Xu·∫•t x·ª©": "unknown"
            }])

            # sanitize types
            input_df["NƒÉm ƒëƒÉng k√Ω"] = pd.to_numeric(input_df["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
            input_df["S·ªë Km ƒë√£ ƒëi"] = pd.to_numeric(input_df["S·ªë Km ƒë√£ ƒëi"], errors="coerce")

            # predict
            try:
                pred = model.predict(input_df)[0]  # pred in same unit as training (Gia_trieu)
            except Exception as e:
                st.error("L·ªói khi d·ª± ƒëo√°n. Ki·ªÉm tra model pipeline.")
                st.write(str(e))
                st.stop()

            # transform features for ISO (and append residual)
            pre = None
            try:
                # try common names for preprocessor step
                if 'pre' in model.named_steps:
                    pre = model.named_steps['pre']
                elif 'preproc' in model.named_steps:
                    pre = model.named_steps['preproc']
                else:
                    # if pipeline saved differently, try first step that is ColumnTransformer
                    for name, step in model.named_steps.items():
                        if hasattr(step, "transform"):
                            pre = step
                            break
            except Exception:
                pre = None

            if pre is None:
                st.error("Kh√¥ng t√¨m th·∫•y preprocessor trong pipeline. Ki·ªÉm tra rf_pipeline.pkl (ph·∫£i ch·ª©a ColumnTransformer t·∫°i named_steps['pre']).")
                st.stop()

            X_trans = pre.transform(input_df)
            if hasattr(X_trans, "toarray"):
                X_trans = X_trans.toarray()
            X_trans = np.asarray(X_trans)  # shape (1, n_features_trans)

            # compute residual for ISO training alignment: ISO expects features + residual (1 column)
            resid_val = (price_input - pred) if price_input > 0 else (0.0 - pred)
            resid_col = np.array(resid_val).reshape(1,1)
            iso_vec = np.hstack([X_trans, resid_col])

            # ensure iso_vec shape matches iso n_features
            try:
                expected = iso.n_features_in_
                if iso_vec.shape[1] != expected:
                    # try using pre.transform then append residual computed in units of training (Gia_trieu)
                    # If mismatch, attempt to warn but continue with best-effort reshape (pad/truncate)
                    st.warning(f"Warning: IsolationForest expects {expected} features but got {iso_vec.shape[1]}. Trying to adjust.")
                    if iso_vec.shape[1] < expected:
                        pad = np.zeros((1, expected - iso_vec.shape[1]))
                        iso_vec = np.hstack([iso_vec, pad])
                    else:
                        iso_vec = iso_vec[:, :expected]
            except Exception:
                # keep going; iso.predict will raise if incompatible
                pass

            # compute iso decision
            try:
                iso_flag = int(iso.predict(iso_vec)[0] == -1)
                iso_score_raw = float(-iso.decision_function(iso_vec)[0])
            except Exception:
                iso_flag = 0
                iso_score_raw = 0.0

            # compute anomaly score using helper (pass full iso_vec (1xN))
            final_score, details = compute_anomaly_score(sample_df=sample_df, brand=brand,
                                                         actual_price=(price_input if price_input>0 else np.nan),
                                                         pred=pred, iso=iso, X_trans_for_iso=iso_vec)

            # determine verdict
            verdict = "B√¨nh th∆∞·ªùng"
            if final_score >= 50 and (details["resid"] < 0):
                verdict = "Gi√° th·∫•p b·∫•t th∆∞·ªùng"
            elif final_score >= 50 and (details["resid"] > 0):
                verdict = "Gi√° cao b·∫•t th∆∞·ªùng"

            # display
            st.markdown("### K·∫øt qu·∫£ d·ª± ƒëo√°n")
            st.write(f"**Gi√° d·ª± ƒëo√°n:** {human_currency(pred)}")
            st.metric("Anomaly Score (0-100)", f"{final_score:.1f}")
            if verdict != "B√¨nh th∆∞·ªùng":
                st.error(f" K·∫øt lu·∫≠n: {verdict}")
            else:
                st.success(" K·∫øt lu·∫≠n: B√¨nh th∆∞·ªùng")

            st.markdown("**L√Ω do:**")
            reasons = []
            if details["resid_z"] > 1.5:
                reasons.append("- Residual Z cao (kh√°c bi·ªát l·ªõn so v·ªõi ph√¢n kh√∫c).")
            if details["violate_minmax"]:
                reasons.append("- Vi ph·∫°m kho·∫£ng gi√° min/max c·ªßa th∆∞∆°ng hi·ªáu.")
            if details["outside_p10p90"]:
                reasons.append("- Gi√° n·∫±m ngo√†i P10‚ÄìP90 theo th∆∞∆°ng hi·ªáu.")
            if details["iso_flag"]:
                reasons.append("- IsolationForest ƒë√°nh d·∫•u b·∫•t th∆∞·ªùng d·ª±a tr√™n vector ƒë·∫∑c tr∆∞ng + resid.")
            if not reasons:
                reasons.append("- Kh√¥ng ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng r√µ r·ªát.")
            for r in reasons:
                st.write(r)

            # detailed table
            detail_table = pd.DataFrame([{
                "Gi√°_d·ª±_ƒëo√°n (Tri·ªáu)": pred,
                "Gi√°_th·ª±c (Tri·ªáu n·∫øu c√≥)": (price_input if price_input>0 else np.nan),
                "Resid": details["resid"],
                "Resid_z": details["resid_z"],
                "Violate_minmax": details["violate_minmax"],
                "Outside_P10_P90": details["outside_p10p90"],
                "ISO_flag": details["iso_flag"],
                "ISO_score_raw": details["iso_score_raw"],
                "AnomalyScore": final_score
            }])
            st.dataframe(detail_table.T, width=900)

            # save pending if requested
            if publish:
                entry = {
                    "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                    "Ti√™u_ƒë·ªÅ": title,
                    "M√¥_t·∫£_chi_ti·∫øt": description,
                    "ƒê·ªãa_ch·ªâ": address,
                    "Th∆∞∆°ng hi·ªáu": brand,
                    "D√≤ng xe": model_name,
                    "NƒÉm ƒëƒÉng k√Ω": year_reg,
                    "S·ªë Km ƒë√£ ƒëi": km,
                    "Lo·∫°i xe": loai,
                    "Dung t√≠ch xe": dungtich,
                    "Gi√°_th·ª±c": (price_input if price_input>0 else np.nan),
                    "Gi√°_d·ª±_ƒëo√°n": float(pred),
                    "anomaly_score": float(final_score),
                    "iso_flag": int(details["iso_flag"]),
                    "status": "pending",
                    "notes": ""
                }
                pid = add_pending(entry)
                st.success(f"K·∫øt qu·∫£ ƒë√£ l∆∞u (id={pid}) v√† ch·ªù Admin duy·ªát.")

            # log
            log_record = {
                "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                "mode": "single",
                "title": title,
                "pred": float(pred),
                "price_input": (price_input if price_input>0 else np.nan),
                "anomaly_score": float(final_score),
                "verdict": verdict
            }
            log_prediction(log_record)

    else:
        # Batch upload
        st.subheader("Upload file CSV/XLSX (batch)")
        st.markdown("File c·∫ßn c√≥ c√°c c·ªôt: Th∆∞∆°ng_hi·ªáu, D√≤ng_xe, Lo·∫°i_xe, Dung_t√≠ch_xe, NƒÉm_ƒëƒÉng_k√Ω, S·ªë_Km_ƒë√£_ƒëi, Gi√° (t√πy ch·ªçn), Kho·∫£ng_gi√°_min, Kho·∫£ng_gi√°_max, Ti√™u_ƒë·ªÅ, M√¥_t·∫£_chi_ti·∫øt, ƒê·ªãa_ch·ªâ")
        uploaded = st.file_uploader("Ch·ªçn file", type=["csv","xlsx"])
        if uploaded is not None:
            try:
                if str(uploaded.name).lower().endswith(".csv"):
                    df_up = pd.read_csv(uploaded)
                else:
                    df_up = pd.read_excel(uploaded)
            except Exception as e:
                st.error("Kh√¥ng th·ªÉ ƒë·ªçc file. Ki·ªÉm tra ƒë·ªãnh d·∫°ng.")
                st.write(e)
                df_up = None

            if df_up is not None:
                missing = ensure_cols_for_upload(df_up)
                if missing:
                    st.error(f"File thi·∫øu c·ªôt b·∫Øt bu·ªôc: {missing}")
                else:
                    # rename upload columns -> training schema
                    rename_map = {
                        "Th∆∞∆°ng_hi·ªáu": "Th∆∞∆°ng hi·ªáu",
                        "D√≤ng_xe": "D√≤ng xe",
                        "Lo·∫°i_xe": "Lo·∫°i xe",
                        "Dung_t√≠ch_xe": "Dung t√≠ch xe",
                        "NƒÉm_ƒëƒÉng_k√Ω": "NƒÉm ƒëƒÉng k√Ω",
                        "S·ªë_Km_ƒë√£_ƒëi": "S·ªë Km ƒë√£ ƒëi",
                        "Gi√°": "Gi√°_th·ª±c",
                        "Kho·∫£ng_gi√°_min": "Kho·∫£ng gi√° min",
                        "Kho·∫£ng_gi√°_max": "Kho·∫£ng gi√° max",
                        "Ti√™u_ƒë·ªÅ": "Ti√™u_ƒë·ªÅ",
                        "M√¥_t·∫£_chi_ti·∫øt": "M√¥_t·∫£_chi_ti·∫øt",
                        "ƒê·ªãa_ch·ªâ": "ƒê·ªãa_ch·ªâ"
                    }
                    df_up = df_up.rename(columns=rename_map)

                    # build input for model
                    model_inputs = []
                    for _, row in df_up.iterrows():
                        input_row = {
                            "Th∆∞∆°ng hi·ªáu": row["Th∆∞∆°ng hi·ªáu"],
                            "D√≤ng xe": row["D√≤ng xe"] if pd.notna(row["D√≤ng xe"]) else "unknown",
                            "NƒÉm ƒëƒÉng k√Ω": int(row["NƒÉm ƒëƒÉng k√Ω"]) if pd.notna(row["NƒÉm ƒëƒÉng k√Ω"]) else CURRENT_YEAR,
                            "S·ªë Km ƒë√£ ƒëi": int(row["S·ªë Km ƒë√£ ƒëi"]) if pd.notna(row["S·ªë Km ƒë√£ ƒëi"]) else 0,
                            "T√¨nh tr·∫°ng": row.get("T√¨nh tr·∫°ng", "ƒê√£ s·ª≠ d·ª•ng"),
                            "Lo·∫°i xe": row["Lo·∫°i xe"],
                            "Dung t√≠ch xe": row["Dung t√≠ch xe"],
                            "Xu·∫•t x·ª©": row.get("Xu·∫•t x·ª©", "unknown")
                        }
                        model_inputs.append(input_row)
                    model_X = pd.DataFrame(model_inputs)

                    # predict batch
                    preds = model.predict(model_X)

                    # transform base features
                    pre = None
                    if 'pre' in model.named_steps:
                        pre = model.named_steps['pre']
                    elif 'preproc' in model.named_steps:
                        pre = model.named_steps['preproc']
                    else:
                        for name, step in model.named_steps.items():
                            if hasattr(step, "transform"):
                                pre = step
                                break
                    if pre is None:
                        st.error("Kh√¥ng t√¨m th·∫•y preprocessor trong pipeline.")
                        st.stop()

                    X_trans = pre.transform(model_X)
                    if hasattr(X_trans, "toarray"):
                        X_trans = X_trans.toarray()
                    X_trans = np.asarray(X_trans)

                    # prepare results
                    results = []
                    for i in range(len(model_X)):
                        # use renamed column Gi√°_th·ª±c
                        actual_price = df_up.loc[i, "Gi√°_th·ª±c"] if "Gi√°_th·ª±c" in df_up.columns else np.nan
                        pred_i = float(preds[i])
                        resid_val = (actual_price - pred_i) if (pd.notna(actual_price) and actual_price>0) else (0.0 - pred_i)
                        iso_vec = np.hstack([X_trans[i].reshape(1,-1), np.array(resid_val).reshape(1,1)])
                        # ensure iso_vec shape matches iso
                        try:
                            expected = iso.n_features_in_
                            if iso_vec.shape[1] != expected:
                                if iso_vec.shape[1] < expected:
                                    iso_vec = np.hstack([iso_vec, np.zeros((1, expected - iso_vec.shape[1]))])
                                else:
                                    iso_vec = iso_vec[:, :expected]
                        except Exception:
                            pass
                        final_score, details = compute_anomaly_score(sample_df=sample_df,
                                                                     brand=model_X.loc[i, "Th∆∞∆°ng hi·ªáu"],
                                                                     actual_price=(actual_price if pd.notna(actual_price) and actual_price>0 else np.nan),
                                                                     pred=pred_i, iso=iso, X_trans_for_iso=iso_vec)
                        verdict = "B√¨nh th∆∞·ªùng"
                        if final_score >= 50 and (details["resid"] < 0):
                            verdict = "Gi√° th·∫•p b·∫•t th∆∞·ªùng"
                        elif final_score >= 50 and (details["resid"] > 0):
                            verdict = "Gi√° cao b·∫•t th∆∞·ªùng"
                        results.append({
                            "Ti√™u_ƒë·ªÅ": df_up.loc[i, "Ti√™u_ƒë·ªÅ"] if "Ti√™u_ƒë·ªÅ" in df_up.columns else "",
                            "Th∆∞∆°ng hi·ªáu": model_X.loc[i, "Th∆∞∆°ng hi·ªáu"],
                            "D√≤ng xe": model_X.loc[i, "D√≤ng xe"],
                            "Gi√°_th·ª±c": actual_price if pd.notna(actual_price) else np.nan,
                            "Gi√°_d·ª±_ƒëo√°n": pred_i,
                            "Resid": details["resid"],
                            "Resid_z": details["resid_z"],
                            "ISO_flag": details["iso_flag"],
                            "ISO_score_raw": details["iso_score_raw"],
                            "AnomalyScore": final_score,
                            "Verdict": verdict
                        })
                        # log entry
                        log_prediction({
                            "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                            "mode": "batch",
                            "file": uploaded.name,
                            "pred": float(pred_i),
                            "price_input": float(actual_price) if pd.notna(actual_price) else np.nan,
                            "anomaly_score": float(final_score),
                            "verdict": verdict
                        })

                    res_df = pd.DataFrame(results)
                    st.success("X·ª≠ l√Ω xong ‚Äî hi·ªÉn th·ªã k·∫øt qu·∫£")
                    st.dataframe(res_df)
                    csv = res_df.to_csv(index=False).encode('utf-8')
                    st.download_button("Export k·∫øt qu·∫£ (CSV)", data=csv, file_name="batch_predictions.csv", mime="text/csv")

# ----------------------
# ANOMALY CHECK (single input quick check)
# ----------------------
if page == "Anomaly Check":
    st.title("üîé Ki·ªÉm tra b·∫•t th∆∞·ªùng (nhanh)")
    with st.form("anom_quick"):
        brand = st.text_input("Th∆∞∆°ng hi·ªáu", value="unknown")
        model_name = st.text_input("D√≤ng xe", value="unknown")
        age = st.slider("Tu·ªïi xe (nƒÉm)", min_value=0, max_value=50, value=3)
        year_registered = int(CURRENT_YEAR - age)
        km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=500000, value=20000, step=1000)
        loai = st.text_input("Lo·∫°i xe", value="unknown")
        dungtich = st.text_input("Dung t√≠ch xe", value="125")
        xuatxu = st.text_input("Xu·∫•t x·ª©", value="unknown")
        gia_thuc = st.number_input("Gi√° th·ª±c (Tri·ªáu VNƒê)", min_value=0.0, value=0.0, step=0.1, format="%.2f")
        submitted = st.form_submit_button("Check Anomaly")
    if submitted:
        input_df = pd.DataFrame([{
            "Th∆∞∆°ng hi·ªáu": brand,
            "D√≤ng xe": model_name,
            "NƒÉm ƒëƒÉng k√Ω": year_registered,
            "S·ªë Km ƒë√£ ƒëi": km,
            "Lo·∫°i xe": loai,
            "Dung t√≠ch xe": dungtich,
            "Xu·∫•t x·ª©": xuatxu
        }])
        input_df["NƒÉm ƒëƒÉng k√Ω"] = pd.to_numeric(input_df["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
        input_df["S·ªë Km ƒë√£ ƒëi"] = pd.to_numeric(input_df["S·ªë Km ƒë√£ ƒëi"], errors="coerce")
        pred = model.predict(input_df)[0]
        # transform & append resid
        pre = model.named_steps.get('pre', model.named_steps.get('preproc', None))
        if pre is None:
            for name, step in model.named_steps.items():
                if hasattr(step, "transform"):
                    pre = step
                    break
        X_trans = pre.transform(input_df)
        if hasattr(X_trans, "toarray"):
            X_trans = X_trans.toarray()
        X_trans = np.asarray(X_trans)
        resid = (gia_thuc - pred) if gia_thuc>0 else (0.0 - pred)
        iso_vec = np.hstack([X_trans, np.array(resid).reshape(1,1)])
        try:
            expected = iso.n_features_in_
            if iso_vec.shape[1] != expected:
                if iso_vec.shape[1] < expected:
                    iso_vec = np.hstack([iso_vec, np.zeros((1, expected - iso_vec.shape[1]))])
                else:
                    iso_vec = iso_vec[:, :expected]
        except Exception:
            pass
        final_score, details = compute_anomaly_score(sample_df=sample_df, brand=brand, actual_price=(gia_thuc if gia_thuc>0 else np.nan), pred=pred, iso=iso, X_trans_for_iso=iso_vec)
        st.metric("Gi√° d·ª± ƒëo√°n (Tri·ªáu)", f"{pred:.2f}")
        st.metric("Anomaly Score (0-100)", f"{final_score:.1f}")
        if final_score >= 50 and details["resid"] < 0:
            st.error("K·∫øt lu·∫≠n: Gi√° th·∫•p b·∫•t th∆∞·ªùng")
        elif final_score >= 50 and details["resid"] > 0:
            st.error("K·∫øt lu·∫≠n: Gi√° cao b·∫•t th∆∞·ªùng")
        else:
            st.success("K·∫øt lu·∫≠n: B√¨nh th∆∞·ªùng")
        st.write(details)

# ----------------------
# ADMIN DASHBOARD
# ----------------------
if page == "Admin Dashboard":
    st.title("üõ†Ô∏è Admin Dashboard")
    st.markdown("Duy·ªát c√°c submissions t·ª´ ng∆∞·ªùi d√πng")
    # show pending
    if PENDING_PATH.exists():
        pending = pd.read_csv(PENDING_PATH)
    else:
        pending = pd.DataFrame(columns=["id","timestamp","Th∆∞∆°ng hi·ªáu","D√≤ng xe","Gi√°_th·ª±c","Gi√°_d·ª±_ƒëo√°n","anomaly_score","iso_flag","status","notes"])
    st.write(f"T·ªïng submissions: {len(pending)}")
    st.dataframe(pending.sort_values("timestamp", ascending=False).head(200))
    # operate
    if len(pending)>0:
        pick = st.selectbox("Ch·ªçn id ƒë·ªÉ thao t√°c", options=["(ch·ªçn)"] + pending["id"].astype(str).tolist())
        if pick != "(ch·ªçn)":
            row = pending[pending["id"].astype(str)==pick].iloc[0]
            st.write(row.to_dict())
            if st.button("Approve"):
                pending.loc[pending["id"]==int(pick),"status"] = "approved"
                pending.to_csv(PENDING_PATH, index=False)
                st.success("ƒê√£ approve")
            if st.button("Reject"):
                pending.loc[pending["id"]==int(pick),"status"] = "rejected"
                pending.to_csv(PENDING_PATH, index=False)
                st.warning("ƒê√£ reject")
            if st.button("Delete"):
                pending = pending[pending["id"]!=int(pick)]
                pending.to_csv(PENDING_PATH, index=False)
                st.info("ƒê√£ x√≥a")

    st.markdown("---")
    st.subheader("Th√¥ng tin model")
    try:
        n_trees = model.named_steps['rf'].n_estimators
    except:
        n_trees = "unknown"
    st.write(f"- RandomForest trees: {n_trees}")
    st.write(f"- Training sample size (app sample): {len(sample_df)}")
    st.write("- Anomaly detector: IsolationForest trained on features + residual")
    if Path(FI_CSV).exists():
        st.dataframe(pd.read_csv(FI_CSV).head(30))
    else:
        st.info("feature_importances.csv not found in repo.")

# ----------------------
# LOGS PAGE
# ----------------------
if page == "Logs":
    st.title(" Logs ho·∫°t ƒë·ªông")
    if LOG_PATH.exists():
        logs = pd.read_csv(LOG_PATH)
        st.write(f"T·ªïng b·∫£n ghi: {len(logs)}")
        st.dataframe(logs.sort_values("timestamp", ascending=False).head(500))
        st.download_button("Export Logs CSV", data=logs.to_csv(index=False).encode('utf-8'), file_name="prediction_logs.csv", mime="text/csv")
    else:
        st.info("Ch∆∞a c√≥ logs n√†o")

# ----------------------
# EVALUATION & REPORT
# ----------------------
if page == "Evaluation & Report":
    st.title(" Evaluation & Report")
    st.subheader("Sample data preview")
    st.dataframe(sample_df.head(200))
    st.subheader("Feature importances")
    try:
        if Path(FI_CSV).exists():
            fi = pd.read_csv(FI_CSV)
            st.dataframe(fi.head(50))
            fig, ax = plt.subplots(figsize=(8,4))
            ax.barh(fi['feature'].head(20)[::-1], fi['importance'].head(20)[::-1])
            st.pyplot(fig)
        else:
            st.info("Kh√¥ng t√¨m th·∫•y file feature_importances.csv")
    except Exception as e:
        st.write("Kh√¥ng th·ªÉ hi·ªÉn th·ªã feature importances:", e)

# ----------------------
# TEAM INFO
# ----------------------
if page == "Team Info":
    st.title("Nh√≥m th·ª±c hi·ªán")
    st.markdown("- H·ªç t√™n HV: Nguyen Thai Binh")
    st.markdown("- Email: thaibinh782k1@gmail.com")
    st.markdown("- Repo: https://github.com/ThaiBinh78/ML07_Project")
    st.markdown("- Ng√†y report: 22/11/2025")
