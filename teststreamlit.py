# app_motor_price.py
import streamlit as st
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import traceback

# ----------------------
# CONFIG
# ----------------------
MODEL_PATH = Path("rf_pipeline.pkl")
ISO_PATH = Path("isolation_forest.pkl")
SAMPLE_PATH = Path("sample_data.csv")
FI_CSV = Path("feature_importances.csv")

PENDING_PATH = Path("pending_listings.csv")
LOG_PATH = Path("prediction_logs.csv")

CURRENT_YEAR = datetime.now().year

st.set_page_config(page_title="D·ª± ƒëo√°n gi√° - Xe m√°y c≈©", layout="wide")


# ----------------------
# Helpers
# ----------------------
@st.cache_resource
def load_models_and_sample(rf_path: Path, iso_path: Path, sample_path: Path):
    """
    Load pipeline, isolation forest, sample dataset. Normalize sample columns for robust downstream usage.
    """
    model = joblib.load(rf_path)
    iso = joblib.load(iso_path)
    sample = pd.read_csv(sample_path)
    sample = sample.rename(columns=lambda x: x.strip())
    # unify price column to 'Gia_trieu' if possible
    if 'Gia_trieu' not in sample.columns and 'Gi√°' in sample.columns:
        sample['Gia_trieu'] = pd.to_numeric(sample['Gi√°'], errors='coerce')
    elif 'Gia_trieu' in sample.columns:
        sample['Gia_trieu'] = pd.to_numeric(sample['Gia_trieu'], errors='coerce')
    for col in ["Kho·∫£ng gi√° min", "Kho·∫£ng gi√° max", "Gi√°"]:
        if col in sample.columns:
            sample[col] = pd.to_numeric(sample[col], errors='coerce')
    return model, iso, sample

def ensure_cols_for_upload(df: pd.DataFrame):
    required = [
        "Th∆∞∆°ng_hi·ªáu","D√≤ng_xe","Lo·∫°i_xe","Dung_t√≠ch_xe",
        "NƒÉm_ƒëƒÉng_k√Ω","S·ªë_Km_ƒë√£_ƒëi","Gi√°","Kho·∫£ng_gi√°_min","Kho·∫£ng_gi√°_max",
        "Ti√™u_ƒë·ªÅ","M√¥_t·∫£_chi_ti·∫øt","ƒê·ªãa_ch·ªâ"
    ]
    missing = [c for c in required if c not in df.columns]
    return missing

def add_pending(entry: dict):
    if PENDING_PATH.exists():
        df = pd.read_csv(PENDING_PATH)
    else:
        df = pd.DataFrame()
    entry_id = int(datetime.utcnow().timestamp() * 1000)
    entry["id"] = entry_id
    df = pd.concat([pd.DataFrame([entry]), df], ignore_index=True, sort=False)
    df.to_csv(PENDING_PATH, index=False)
    return entry_id

def log_prediction(record: dict):
    if LOG_PATH.exists():
        logs = pd.read_csv(LOG_PATH)
    else:
        logs = pd.DataFrame()
    logs = pd.concat([pd.DataFrame([record]), logs], ignore_index=True, sort=False)
    logs.to_csv(LOG_PATH, index=False)

def human_currency_trieu(x):
    try:
        v = float(x)
        return f"{v:,.2f} Tri·ªáu"
    except Exception:
        return x

def compute_anomaly_score(sample_df, brand, actual_price, pred, iso, X_trans_for_iso):
    """
    Returns numeric final_score (kept for internal use) and details dict.
    X_trans_for_iso: array or flattened vector that already includes residual as last column OR includes features only;
                     function will accept both (if no residual present, assumes residual computed outside and appended).
    """
    try:
        resid = (actual_price - pred) if (actual_price is not None and not pd.isna(actual_price)) else (0.0 - pred)
    except Exception:
        resid = 0.0 - pred

    # try find brand column
    if 'Th∆∞∆°ng hi·ªáu' in sample_df.columns:
        sample_brand = sample_df[sample_df['Th∆∞∆°ng hi·ªáu'] == brand].copy()
    elif 'Th∆∞∆°ng_hi·ªáu' in sample_df.columns:
        sample_brand = sample_df[sample_df['Th∆∞∆°ng_hi·ªáu'] == brand].copy()
    else:
        sample_brand = pd.DataFrame()

    # residual z: prefer brand IQR, else global std
    if len(sample_brand) >= 10 and 'Gia_trieu' in sample_brand.columns:
        iqr = (sample_brand['Gia_trieu'].quantile(0.75) - sample_brand['Gia_trieu'].quantile(0.25)) or 1.0
        resid_z = abs(resid) / max(iqr, 1e-6)
    else:
        global_std = sample_df['Gia_trieu'].std() if 'Gia_trieu' in sample_df.columns else 1.0
        resid_z = abs(resid) / max(1.0, global_std)

    # min/max check (brand-level)
    min_price = sample_brand['Kho·∫£ng gi√° min'].min() if ('Kho·∫£ng gi√° min' in sample_brand.columns and len(sample_brand)>0) else np.nan
    max_price = sample_brand['Kho·∫£ng gi√° max'].max() if ('Kho·∫£ng gi√° max' in sample_brand.columns and len(sample_brand)>0) else np.nan
    violate_minmax = int((not pd.isna(min_price) and (actual_price < min_price)) or (not pd.isna(max_price) and (actual_price > max_price)))

    # p10/p90
    p10 = sample_brand['Gia_trieu'].quantile(0.10) if (len(sample_brand)>0 and 'Gia_trieu' in sample_brand.columns) else np.nan
    p90 = sample_brand['Gia_trieu'].quantile(0.90) if (len(sample_brand)>0 and 'Gia_trieu' in sample_brand.columns) else np.nan
    outside_p10p90 = int((not pd.isna(p10) and actual_price < p10) or (not pd.isna(p90) and actual_price > p90))

    # iso: ensure iso_vec is 2D and shape matches iso.n_features_in_
    iso_vec = X_trans_for_iso
    if hasattr(iso_vec, "toarray"):
        iso_vec = iso_vec.toarray()
    iso_vec = np.asarray(iso_vec)
    if iso_vec.ndim == 1:
        iso_vec = iso_vec.reshape(1, -1)

    try:
        expected = iso.n_features_in_
        if iso_vec.shape[1] != expected:
            # pad with zeros or truncate
            if iso_vec.shape[1] < expected:
                pad = np.zeros((iso_vec.shape[0], expected - iso_vec.shape[1]))
                iso_vec = np.hstack([iso_vec, pad])
            else:
                iso_vec = iso_vec[:, :expected]
        iso_score_raw = - float(iso.decision_function(iso_vec)[0])
        iso_flag = int(iso.predict(iso_vec)[0] == -1)
    except Exception:
        iso_score_raw = 0.0
        iso_flag = 0

    # combine into final numeric score (kept for logging/back-end)
    w1, w2, w3, w4 = 0.4, 0.2, 0.2, 0.2
    score1 = min(1.0, resid_z / 3.0) * 100.0
    score2 = violate_minmax * 100.0
    score3 = outside_p10p90 * 100.0
    score4 = min(1.0, iso_score_raw / 0.5) * 100.0
    final_score = float(w1*score1 + w2*score2 + w3*score3 + w4*score4)

    return final_score, {
        "resid": float(resid),
        "resid_z": float(resid_z),
        "violate_minmax": int(violate_minmax),
        "outside_p10p90": int(outside_p10p90),
        "iso_flag": int(iso_flag),
        "iso_score_raw": float(iso_score_raw),
        "score_components": {"score1": score1, "score2": score2, "score3": score3, "score4": score4}
    }

# ----------------------
# Load models & sample (safe)
# ----------------------
try:
    missing = [str(p) for p in [MODEL_PATH, ISO_PATH, SAMPLE_PATH] if not Path(p).exists()]
    if missing:
        raise FileNotFoundError(f"Missing files: {missing}. Make sure these files are in the same folder as this app.")
    model, iso, sample_df = load_models_and_sample(MODEL_PATH, ISO_PATH, SAMPLE_PATH)
except Exception as e:
    st.error("Kh√¥ng th·ªÉ load model/sample. Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n & file c√≥ trong repo hay kh√¥ng.")
    st.write(str(e))
    st.write(traceback.format_exc())
    st.stop()

# ----------------------
# Sidebar & Menu
# ----------------------
st.sidebar.title("Menu")
if Path("xe_may_cu.jpg").exists():
    st.sidebar.image("xe_may_cu.jpg", use_column_width=True)
page = st.sidebar.radio("Ch·ªçn m·ª•c", ["B√†i to√°n nghi·ªáp v·ª• ", "D·ª± ƒëo√°n gi√°", "Ki·ªÉm tra b·∫•t th∆∞·ªùng", "Ch·∫ø ƒë·ªô qu·∫£n tr·ªã vi√™n", "Nh·∫≠t k√Ω h·ªá th·ªëng", "ƒê√°nh gi√° & B√°o c√°o k·∫øt qu·∫£", "Th√¥ng tin nh√≥m th·ª±c hi·ªán"])

# ----------------------
# B√†i to√°n nghi·ªáp v·ª• 
# ----------------------
def render_business_problem():
    st.title("B√†i to√°n nghi·ªáp v·ª• ")
    st.markdown("""
- **M·ª•c ti√™u:** D·ª± ƒëo√°n gi√° b√°n h·ª£p l√Ω cho xe m√°y c≈© v√† ph√°t hi·ªán tin ƒëƒÉng gi√° b·∫•t th∆∞·ªùng.
- **Input:** Th∆∞∆°ng hi·ªáu, D√≤ng xe, NƒÉm ƒëƒÉng k√Ω, S·ªë Km, Lo·∫°i xe, Dung t√≠ch, Xu·∫•t x·ª©, (Gi√° th·ª±c - t√πy ch·ªçn).
- **Output:** Gi√° d·ª± ƒëo√°n (Tri·ªáu VNƒê) + K·∫øt lu·∫≠n b·∫±ng l·ªùi (d·∫°ng t∆∞ v·∫•n, d·ªÖ hi·ªÉu).
- **Ph∆∞∆°ng ph√°p:** RandomForest cho d·ª± ƒëo√°n; IsolationForest + th·ªëng k√™ cho ph√°t hi·ªán b·∫•t th∆∞·ªùng.
    """)
if page == "B√†i to√°n nghi·ªáp v·ª• ":
    render_business_problem()

# ----------------------
# Prediction page
# ----------------------
if page == "D·ª± ƒëo√°n gi√°":
    st.title("D·ª± ƒëo√°n gi√° & Ki·ªÉm tra b·∫•t th∆∞·ªùng ‚Äî Xe m√°y c≈©")
    st.markdown("Ch·ªçn ch·∫ø ƒë·ªô nh·∫≠p: Nh·∫≠p tay ho·∫∑c Upload file CSV/XLSX (c·ªôt chu·∫©n).")

    mode = st.radio("Ch·ªçn ch·∫ø ƒë·ªô", ["Nh·∫≠p tay", "Upload file (CSV/XLSX)"], index=0)

    if mode == "Nh·∫≠p tay":
        st.subheader("Nh·∫≠p chi ti·∫øt tin ƒëƒÉng")
        with st.form("form_single", clear_on_submit=False):
            c1, c2 = st.columns([2,1])
            with c1:
                title = st.text_input("Ti√™u ƒë·ªÅ tin ƒëƒÉng", value="B√°n SH Mode 125 ch√≠nh ch·ªß")
                description = st.text_area("M√¥ t·∫£ chi ti·∫øt", value="Xe ƒë·∫πp, bao test, bi·ªÉn s·ªë TP, gi√° c√≥ th∆∞∆°ng l∆∞·ª£ng.")
                address = st.text_input("ƒê·ªãa ch·ªâ", value="Qu·∫≠n 1, TP. H·ªì Ch√≠ Minh")
                brands = sample_df['Th∆∞∆°ng hi·ªáu'].dropna().unique().tolist() if 'Th∆∞∆°ng hi·ªáu' in sample_df.columns else ['unknown']
                brand = st.selectbox("Th∆∞∆°ng hi·ªáu", options=sorted(brands))
                model_name = st.text_input("D√≤ng xe", value="")
                loai_values = sample_df['Lo·∫°i xe'].dropna().unique().tolist() if 'Lo·∫°i xe' in sample_df.columns else ['unknown']
                loai = st.selectbox("Lo·∫°i xe", options=sorted(loai_values))
            with c2:
                dungtich = st.text_input("Dung t√≠ch xe (v√≠ d·ª• '100 - 175 cc' ho·∫∑c '125')", value="125")
                xuatxu = st.text_input("Xu·∫•t x·ª©", value="unknown")
                age = st.slider("Tu·ªïi xe (nƒÉm)", 0, 50, 3)
                year_reg = int(CURRENT_YEAR - age)
                st.write(f"NƒÉm ƒëƒÉng k√Ω (t∆∞∆°ng ·ª©ng): {year_reg}")
                km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=500000, value=20000, step=1000)
                price_input = st.number_input("Gi√° th·ª±c (Tri·ªáu VNƒê) ‚Äî n·∫øu mu·ªën (t√πy ch·ªçn)", min_value=0.0, value=0.0, step=0.1, format="%.2f")
                price_min = st.number_input("Kho·∫£ng_gi√°_min (Tri·ªáu) ‚Äî c√≥ th·ªÉ b·ªè tr·ªëng", min_value=0.0, value=0.0, step=0.1, format="%.2f")
                price_max = st.number_input("Kho·∫£ng_gi√°_max (Tri·ªáu) ‚Äî c√≥ th·ªÉ b·ªè tr·ªëng", min_value=0.0, value=0.0, step=0.1, format="%.2f")

            publish = st.checkbox("L∆∞u ƒë·ªÉ Admin duy·ªát (ƒëƒÉng b√°n)")
            submitted = st.form_submit_button("Predict & Check Anomaly")

        if submitted:
            input_df = pd.DataFrame([{
                "Th∆∞∆°ng hi·ªáu": brand,
                "D√≤ng xe": model_name if model_name.strip()!="" else "unknown",
                "NƒÉm ƒëƒÉng k√Ω": year_reg,
                "S·ªë Km ƒë√£ ƒëi": km,
                "T√¨nh tr·∫°ng": "ƒê√£ s·ª≠ d·ª•ng",
                "Lo·∫°i xe": loai,
                "Dung t√≠ch xe": dungtich,
                "Xu·∫•t x·ª©": xuatxu
            }])
            input_df["NƒÉm ƒëƒÉng k√Ω"] = pd.to_numeric(input_df["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
            input_df["S·ªë Km ƒë√£ ƒëi"] = pd.to_numeric(input_df["S·ªë Km ƒë√£ ƒëi"], errors="coerce")

            # predict
            try:
                pred = float(model.predict(input_df)[0])
            except Exception as e:
                st.error("L·ªói khi d·ª± ƒëo√°n ‚Äî ki·ªÉm tra pipeline model.")
                st.write(str(e))
                st.stop()

            # find preprocessor inside pipeline
            pre = None
            try:
                if 'pre' in model.named_steps:
                    pre = model.named_steps['pre']
                elif 'preproc' in model.named_steps:
                    pre = model.named_steps['preproc']
                else:
                    for name, step in model.named_steps.items():
                        if hasattr(step, "transform"):
                            pre = step
                            break
            except Exception:
                pre = None

            if pre is None:
                st.error("Kh√¥ng t√¨m th·∫•y preprocessor trong pipeline. Ki·ªÉm tra rf_pipeline.pkl")
                st.stop()

            X_trans = pre.transform(input_df)
            if hasattr(X_trans, "toarray"):
                X_trans = X_trans.toarray()
            X_trans = np.asarray(X_trans)  # shape (1, n_features)

            # residual (in same units as training, Gia_trieu)
            resid_val = (price_input - pred) if price_input > 0 else (0.0 - pred)
            iso_vec = np.hstack([X_trans, np.array(resid_val).reshape(1,1)])

            # adjust iso_vec to expected features
            try:
                expected = iso.n_features_in_
                if iso_vec.shape[1] != expected:
                    if iso_vec.shape[1] < expected:
                        iso_vec = np.hstack([iso_vec, np.zeros((1, expected - iso_vec.shape[1]))])
                    else:
                        iso_vec = iso_vec[:, :expected]
            except Exception:
                pass

            # compute anomaly numeric details (kept for logs)
            final_score, details = compute_anomaly_score(sample_df=sample_df, brand=brand,
                                                         actual_price=(price_input if price_input>0 else np.nan),
                                                         pred=pred, iso=iso, X_trans_for_iso=iso_vec)

            # determine verdict and user-friendly explanation (C-style: t∆∞ v·∫•n + r·ªßi ro)
            verdict = "B√¨nh th∆∞·ªùng"
            if final_score >= 50 and (details["resid"] < 0):
                verdict = "Gi√° th·∫•p b·∫•t th∆∞·ªùng"
            elif final_score >= 50 and (details["resid"] > 0):
                verdict = "Gi√° cao b·∫•t th∆∞·ªùng"

            # Build human-friendly explanation (per your choice C)
            if verdict == "B√¨nh th∆∞·ªùng":
                explanation = ("Gi√° b·∫°n nh·∫≠p hi·ªán n·∫±m trong v√πng an to√†n cho d√≤ng xe n√†y. "
                               "Ng∆∞·ªùi mua v√† ng∆∞·ªùi b√°n c√≥ th·ªÉ th∆∞∆°ng l∆∞·ª£ng th√™m ‚Äî m·ª©c gi√° n√†y √≠t kh·∫£ nƒÉng l√† l·ª´a ƒë·∫£o.")
            else:
                if verdict == "Gi√° th·∫•p b·∫•t th∆∞·ªùng":
                    explanation = ("Gi√° n√†y th·∫•p h∆°n th√¥ng th∆∞·ªùng. N·∫øu b·∫°n l√† ng∆∞·ªùi b√°n, ki·ªÉm tra: bi·ªÉn s·ªë t·ªânh, "
                                   "xe c√≥ s·ª≠a ch·ªØa/ƒë√£ thay m√°y, odo b·∫•t th∆∞·ªùng, ho·∫∑c b·∫°n nh·∫≠p nh·∫ßm ƒë∆°n v·ªã (ng√†n vs tri·ªáu). "
                                   "N·∫øu b·∫°n l√† ng∆∞·ªùi mua, h√£y c·∫©n tr·ªçng: y√™u c·∫ßu xem tr·ª±c ti·∫øp v√† gi·∫•y t·ªù.")
                else:
                    explanation = ("Gi√° n√†y cao b·∫•t th∆∞·ªùng so v·ªõi th·ªã tr∆∞·ªùng. Ki·ªÉm tra: th√¥ng tin xe c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng, "
                                   "ng∆∞·ªùi b√°n c√≥ b·∫±ng ch·ª©ng ch√≠nh ch·ªß hay l·ªãch s·ª≠ s·ª≠a ch·ªØa r√µ r√†ng hay kh√¥ng.")

            # Provide detailed bullet suggestions when abnormal (6‚Äì8 items)
            suggestions = []
            if verdict != "B√¨nh th∆∞·ªùng":
                suggestions = [
                    "Ki·ªÉm tra l·∫°i: b·∫°n ƒë√£ nh·∫≠p ƒë√∫ng ƒë∆°n v·ªã (Tri·ªáu) ch∆∞a (ƒë√¥i khi nh·∫≠p nh·∫ßm ng√†n).",
                    "Ki·ªÉm tra bi·ªÉn s·ªë (t·ªânh/th√†nh) so v·ªõi ƒë·ªãa ch·ªâ ng∆∞·ªùi b√°n.",
                    "Y√™u c·∫ßu h√¨nh ·∫£nh/gi·∫•y t·ªù chi ti·∫øt: ch√≠nh ch·ªß, ƒëƒÉng ki·ªÉm, h√≥a ƒë∆°n s·ª≠a ch·ªØa (n·∫øu c√≥).",
                    "Ki·ªÉm tra odo / s·ªë km ‚Äî odo cao khi·∫øn gi√° th·∫•p l√† h·ª£p l√Ω.",
                    "Xem l·ªãch s·ª≠ thay th·∫ø l·ªõn (thay m√°y, thay khung) ‚Äî ƒëi·ªÅu n√†y ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn gi√°.",
                    "Ng∆∞·ªùi mua n√™n h·∫πn xem tr·ª±c ti·∫øp, th·ª≠ xe; ng∆∞·ªùi b√°n n√™n th√™m m√¥ t·∫£ chi ti·∫øt & h√¨nh ·∫£nh r√µ r√†ng."
                ]
            else:
                suggestions = [
                    "Gi·ªØ m√¥ t·∫£ r√µ r√†ng (ƒë·ªùi xe, km, ch√≠nh ch·ªß) ƒë·ªÉ tƒÉng tin c·∫≠y.",
                    "ƒê√°nh gi√° k·ªπ tr∆∞·ªõc khi th∆∞∆°ng l∆∞·ª£ng ‚Äî gi√° ƒëang ·ªü v√πng an to√†n."
                ]

            # Display to user (no numeric anomaly score shown)
            st.markdown("### K·∫øt qu·∫£ d·ª± ƒëo√°n")
            st.write(f"**Gi√° d·ª± ƒëo√°n:** {human_currency_trieu(pred)}")
            st.markdown(f"**K·∫øt lu·∫≠n:** **{verdict}**")
            st.markdown("**Gi·∫£i th√≠ch (d·ªÖ hi·ªÉu):**")
            st.write(explanation)
            st.markdown("**L√Ω do chi ti·∫øt:**")
            # include human-readable reasons derived from details
            reasons = []
            if details["resid_z"] > 1.5:
                reasons.append("Gi√° ch√™nh l·ªõn so v·ªõi ph√¢n kh√∫c (residual cao).")
            if details["violate_minmax"]:
                reasons.append("Gi√° n·∫±m ngo√†i kho·∫£ng gi√° min/max c·ªßa th∆∞∆°ng hi·ªáu.")
            if details["outside_p10p90"]:
                reasons.append("Gi√° n·∫±m ngo√†i v√πng P10‚ÄìP90 (kh√°c bi·ªát so v·ªõi 90% m·∫´u).")
            if details["iso_flag"]:
                reasons.append("M·∫´u c√≥ ƒë·∫∑c ƒëi·ªÉm kh√°c bi·ªát (m·ªôt m√¥ h√¨nh ph√°t hi·ªán b·∫•t th∆∞·ªùng ƒë√°nh d·∫•u).")
            if not reasons:
                reasons.append("Kh√¥ng ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng r√µ r·ªát trong d·ªØ li·ªáu m·∫´u.")
            for r in reasons:
                st.write("- " + r)

            st.markdown("**G·ª£i √Ω / H∆∞·ªõng x·ª≠ l√Ω**")
            for s in suggestions:
                st.write("- " + s)

            # Detailed table (for power users)
            detail_table = pd.DataFrame([{
                "Gi√°_d·ª±_ƒëo√°n (Tri·ªáu)": pred,
                "Gi√°_th·ª±c nh·∫≠p (Tri·ªáu n·∫øu c√≥)": (price_input if price_input>0 else np.nan),
                "Resid": details["resid"],
                "Resid_z": details["resid_z"],
                "Violate_minmax": details["violate_minmax"],
                "Outside_P10_P90": details["outside_p10p90"],
                "ISO_flag": details["iso_flag"],
                "ISO_score_raw": details["iso_score_raw"],
                "AnomalyScore_internal": final_score
            }])
            st.dataframe(detail_table.T, width=900)

            # save pending if requested
            if publish:
                entry = {
                    "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                    "Ti√™u_ƒë·ªÅ": title,
                    "M√¥_t·∫£_chi_ti·∫øt": description,
                    "ƒê·ªãa_ch·ªâ": address,
                    "Th∆∞∆°ng hi·ªáu": brand,
                    "D√≤ng xe": model_name,
                    "NƒÉm ƒëƒÉng k√Ω": year_reg,
                    "S·ªë Km ƒë√£ ƒëi": km,
                    "Lo·∫°i xe": loai,
                    "Dung t√≠ch xe": dungtich,
                    "Xu·∫•t x·ª©": xuatxu,
                    "Gi√°_th·ª±c": (price_input if price_input>0 else np.nan),
                    "Gi√°_d·ª±_ƒëo√°n": float(pred),
                    "anomaly_score": float(final_score),
                    "iso_flag": int(details["iso_flag"]),
                    "status": "pending",
                    "notes": ""
                }
                pid = add_pending(entry)
                st.success(f"K·∫øt qu·∫£ ƒë√£ l∆∞u (id={pid}) v√† ch·ªù Admin duy·ªát.")

            # log (keeps numeric score for admin / analysis)
            log_prediction({
                "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                "mode": "single",
                "title": title,
                "pred": float(pred),
                "price_input": (price_input if price_input>0 else np.nan),
                "anomaly_score": float(final_score),
                "verdict": verdict
            })

    else:
        # Batch upload
        st.subheader("Upload file CSV/XLSX (batch)")
        st.markdown("File c·∫ßn c√≥ c√°c c·ªôt: Th∆∞∆°ng_hi·ªáu, D√≤ng_xe, Lo·∫°i_xe, Dung_t√≠ch_xe, NƒÉm_ƒëƒÉng_k√Ω, S·ªë_Km_ƒë√£_ƒëi, Gi√° (t√πy ch·ªçn), Kho·∫£ng_gi√°_min, Kho·∫£ng_gi√°_max, Ti√™u_ƒë·ªÅ, M√¥_t·∫£_chi_ti·∫øt, ƒê·ªãa_ch·ªâ")
        uploaded = st.file_uploader("Ch·ªçn file", type=["csv","xlsx"])
        if uploaded is not None:
            try:
                if str(uploaded.name).lower().endswith(".csv"):
                    df_up = pd.read_csv(uploaded)
                else:
                    df_up = pd.read_excel(uploaded)
            except Exception as e:
                st.error("Kh√¥ng th·ªÉ ƒë·ªçc file. Ki·ªÉm tra ƒë·ªãnh d·∫°ng.")
                st.write(e)
                df_up = None

            if df_up is not None:
                missing = ensure_cols_for_upload(df_up)
                if missing:
                    st.error(f"File thi·∫øu c·ªôt b·∫Øt bu·ªôc: {missing}")
                else:
                    rename_map = {
                        "Th∆∞∆°ng_hi·ªáu": "Th∆∞∆°ng hi·ªáu",
                        "D√≤ng_xe": "D√≤ng xe",
                        "Lo·∫°i_xe": "Lo·∫°i xe",
                        "Dung_t√≠ch_xe": "Dung t√≠ch xe",
                        "NƒÉm_ƒëƒÉng_k√Ω": "NƒÉm ƒëƒÉng k√Ω",
                        "S·ªë_Km_ƒë√£_ƒëi": "S·ªë Km ƒë√£ ƒëi",
                        "Gi√°": "Gi√°_th·ª±c",
                        "Kho·∫£ng_gi√°_min": "Kho·∫£ng gi√° min",
                        "Kho·∫£ng_gi√°_max": "Kho·∫£ng gi√° max",
                        "Ti√™u_ƒë·ªÅ": "Ti√™u_ƒë·ªÅ",
                        "M√¥_t·∫£_chi_ti·∫øt": "M√¥_t·∫£_chi_ti·∫øt",
                        "ƒê·ªãa_ch·ªâ": "ƒê·ªãa_ch·ªâ"
                    }
                    df_up = df_up.rename(columns=rename_map)
                    # build inputs
                    model_inputs = []
                    for _, row in df_up.iterrows():
                        model_inputs.append({
                            "Th∆∞∆°ng hi·ªáu": row["Th∆∞∆°ng hi·ªáu"],
                            "D√≤ng xe": row["D√≤ng xe"] if pd.notna(row["D√≤ng xe"]) else "unknown",
                            "NƒÉm ƒëƒÉng k√Ω": int(row["NƒÉm ƒëƒÉng k√Ω"]) if pd.notna(row["NƒÉm ƒëƒÉng k√Ω"]) else CURRENT_YEAR,
                            "S·ªë Km ƒë√£ ƒëi": int(row["S·ªë Km ƒë√£ ƒëi"]) if pd.notna(row["S·ªë Km ƒë√£ ƒëi"]) else 0,
                            "T√¨nh tr·∫°ng": row.get("T√¨nh tr·∫°ng", "ƒê√£ s·ª≠ d·ª•ng"),
                            "Lo·∫°i xe": row["Lo·∫°i xe"],
                            "Dung t√≠ch xe": row["Dung t√≠ch xe"],
                            "Xu·∫•t x·ª©": row.get("Xu·∫•t x·ª©", "unknown")
                        })
                    model_X = pd.DataFrame(model_inputs)
                    preds = model.predict(model_X)
                    # find preprocessor
                    pre = None
                    if 'pre' in model.named_steps:
                        pre = model.named_steps['pre']
                    elif 'preproc' in model.named_steps:
                        pre = model.named_steps['preproc']
                    else:
                        for name, step in model.named_steps.items():
                            if hasattr(step, "transform"):
                                pre = step
                                break
                    if pre is None:
                        st.error("Kh√¥ng t√¨m th·∫•y preprocessor trong pipeline.")
                        st.stop()
                    X_trans = pre.transform(model_X)
                    if hasattr(X_trans, "toarray"):
                        X_trans = X_trans.toarray()
                    X_trans = np.asarray(X_trans)

                    results = []
                    for i in range(len(model_X)):
                        actual_price = df_up.loc[i, "Gi√°_th·ª±c"] if "Gi√°_th·ª±c" in df_up.columns else np.nan
                        pred_i = float(preds[i])
                        resid_val = (actual_price - pred_i) if (pd.notna(actual_price) and actual_price>0) else (0.0 - pred_i)
                        iso_vec = np.hstack([X_trans[i].reshape(1,-1), np.array(resid_val).reshape(1,1)])
                        # ensure iso_vec size matches
                        try:
                            expected = iso.n_features_in_
                            if iso_vec.shape[1] != expected:
                                if iso_vec.shape[1] < expected:
                                    iso_vec = np.hstack([iso_vec, np.zeros((1, expected - iso_vec.shape[1]))])
                                else:
                                    iso_vec = iso_vec[:, :expected]
                        except Exception:
                            pass
                        final_score, details = compute_anomaly_score(sample_df=sample_df,
                                                                     brand=model_X.loc[i, "Th∆∞∆°ng hi·ªáu"],
                                                                     actual_price=(actual_price if pd.notna(actual_price) and actual_price>0 else np.nan),
                                                                     pred=pred_i, iso=iso, X_trans_for_iso=iso_vec)
                        verdict = "B√¨nh th∆∞·ªùng"
                        if final_score >= 50 and (details["resid"] < 0):
                            verdict = "Gi√° th·∫•p b·∫•t th∆∞·ªùng"
                        elif final_score >= 50 and (details["resid"] > 0):
                            verdict = "Gi√° cao b·∫•t th∆∞·ªùng"

                        # Generate human explanation text (short)
                        if verdict == "B√¨nh th∆∞·ªùng":
                            explanation = "Gi√° n·∫±m trong v√πng an to√†n c·ªßa m·∫´u."
                        elif verdict == "Gi√° th·∫•p b·∫•t th∆∞·ªùng":
                            explanation = "Gi√° th·∫•p h∆°n ƒëa s·ªë m·∫´u; h√£y ki·ªÉm tra k·ªπ gi·∫•y t·ªù v√† t√¨nh tr·∫°ng xe."
                        else:
                            explanation = "Gi√° cao h∆°n ƒëa s·ªë m·∫´u; ki·ªÉm tra m√£ tin v√† gi·∫•y t·ªù."

                        results.append({
                            "Ti√™u_ƒë·ªÅ": df_up.loc[i, "Ti√™u_ƒë·ªÅ"] if "Ti√™u_ƒë·ªÅ" in df_up.columns else "",
                            "Th∆∞∆°ng hi·ªáu": model_X.loc[i, "Th∆∞∆°ng hi·ªáu"],
                            "D√≤ng xe": model_X.loc[i, "D√≤ng xe"],
                            "Gi√°_th·ª±c": actual_price if pd.notna(actual_price) else np.nan,
                            "Gi√°_d·ª±_ƒëo√°n": pred_i,
                            "Verdict": verdict,
                            "Explanation": explanation,
                            "AnomalyScore_internal": final_score
                        })
                        log_prediction({
                            "timestamp": datetime.now().isoformat(sep=' ', timespec='seconds'),
                            "mode": "batch",
                            "file": uploaded.name,
                            "pred": float(pred_i),
                            "price_input": float(actual_price) if pd.notna(actual_price) else np.nan,
                            "anomaly_score": float(final_score),
                            "verdict": verdict
                        })
                    res_df = pd.DataFrame(results)
                    st.success("X·ª≠ l√Ω xong ‚Äî hi·ªÉn th·ªã k·∫øt qu·∫£")
                    st.dataframe(res_df)
                    csv = res_df.to_csv(index=False).encode('utf-8')
                    st.download_button("Export k·∫øt qu·∫£ (CSV)", data=csv, file_name="batch_predictions.csv", mime="text/csv")

# ----------------------
# Anomaly Check (quick)
# ----------------------
if page == "Anomaly Check":
    st.title("üîé Ki·ªÉm tra b·∫•t th∆∞·ªùng (nhanh)")
    with st.form("anom_quick"):
        brand = st.text_input("Th∆∞∆°ng hi·ªáu", value="unknown")
        model_name = st.text_input("D√≤ng xe", value="unknown")
        age = st.slider("Tu·ªïi xe (nƒÉm)", min_value=0, max_value=50, value=3)
        year_registered = int(CURRENT_YEAR - age)
        km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=500000, value=20000, step=1000)
        loai = st.text_input("Lo·∫°i xe", value="unknown")
        dungtich = st.text_input("Dung t√≠ch xe", value="125")
        xuatxu = st.text_input("Xu·∫•t x·ª©", value="unknown")
        gia_thuc = st.number_input("Gi√° th·ª±c (Tri·ªáu VNƒê)", min_value=0.0, value=0.0, step=0.1, format="%.2f")
        submitted = st.form_submit_button("Check Anomaly")
    if submitted:
        input_df = pd.DataFrame([{
            "Th∆∞∆°ng hi·ªáu": brand,
            "D√≤ng xe": model_name,
            "NƒÉm ƒëƒÉng k√Ω": year_registered,
            "S·ªë Km ƒë√£ ƒëi": km,
            "Lo·∫°i xe": loai,
            "Dung t√≠ch xe": dungtich,
            "Xu·∫•t x·ª©": xuatxu
        }])
        input_df["NƒÉm ƒëƒÉng k√Ω"] = pd.to_numeric(input_df["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
        input_df["S·ªë Km ƒë√£ ƒëi"] = pd.to_numeric(input_df["S·ªë Km ƒë√£ ƒëi"], errors="coerce")
        pred = float(model.predict(input_df)[0])
        # transform & append resid
        pre = None
        if 'pre' in model.named_steps:
            pre = model.named_steps['pre']
        elif 'preproc' in model.named_steps:
            pre = model.named_steps['preproc']
        else:
            for name, step in model.named_steps.items():
                if hasattr(step, "transform"):
                    pre = step
                    break
        X_trans = pre.transform(input_df)
        if hasattr(X_trans, "toarray"):
            X_trans = X_trans.toarray()
        X_trans = np.asarray(X_trans)
        resid = (gia_thuc - pred) if gia_thuc>0 else (0.0 - pred)
        iso_vec = np.hstack([X_trans, np.array(resid).reshape(1,1)])
        try:
            expected = iso.n_features_in_
            if iso_vec.shape[1] != expected:
                if iso_vec.shape[1] < expected:
                    iso_vec = np.hstack([iso_vec, np.zeros((1, expected - iso_vec.shape[1]))])
                else:
                    iso_vec = iso_vec[:, :expected]
        except Exception:
            pass
        final_score, details = compute_anomaly_score(sample_df=sample_df, brand=brand, actual_price=(gia_thuc if gia_thuc>0 else np.nan), pred=pred, iso=iso, X_trans_for_iso=iso_vec)
        # human-friendly
        if final_score >= 50 and details["resid"] < 0:
            verdict = "Gi√° th·∫•p b·∫•t th∆∞·ªùng"
            explanation = ("Gi√° th·∫•p h∆°n b√¨nh th∆∞·ªùng ‚Äî ng∆∞·ªùi mua n√™n c·∫©n tr·ªçng; ng∆∞·ªùi b√°n h√£y ki·ªÉm tra l·∫°i th√¥ng tin.")
        elif final_score >= 50 and details["resid"] > 0:
            verdict = "Gi√° cao b·∫•t th∆∞·ªùng"
            explanation = ("Gi√° cao h∆°n b√¨nh th∆∞·ªùng ‚Äî ki·ªÉm tra t√≠nh x√°c th·ª±c h·ªì s∆° v√† gi·∫•y t·ªù.")
        else:
            verdict = "B√¨nh th∆∞·ªùng"
            explanation = ("Gi√° n·∫±m trong v√πng an to√†n; th∆∞·ªùng c√≥ th·ªÉ ƒëƒÉng b√°n ho·∫∑c th∆∞∆°ng l∆∞·ª£ng.")
        st.metric("Gi√° d·ª± ƒëo√°n (Tri·ªáu)", f"{pred:.2f}")
        st.write("K·∫øt lu·∫≠n:", verdict)
        st.write("Gi·∫£i th√≠ch:", explanation)
        st.write("Chi ti·∫øt k·ªπ thu·∫≠t (d√†nh cho admin/ analyst):")
        st.json(details)

# ----------------------
# Admin Dashboard (Approve / Reject only)
# ----------------------
if page == "Ch·∫ø ƒë·ªô qu·∫£n tr·ªã vi√™n":
    st.title(" Ch·∫ø ƒë·ªô qu·∫£n tr·ªã vi√™n")
    st.markdown("Duy·ªát c√°c submissions t·ª´ ng∆∞·ªùi d√πng")
    if PENDING_PATH.exists():
        pending = pd.read_csv(PENDING_PATH)
    else:
        pending = pd.DataFrame(columns=["id","timestamp","Th∆∞∆°ng hi·ªáu","D√≤ng xe","Gi√°_th·ª±c","Gi√°_d·ª±_ƒëo√°n","anomaly_score","iso_flag","status","notes"])
    st.write(f"T·ªïng submissions: {len(pending)}")
    st.dataframe(pending.sort_values("timestamp", ascending=False).head(200))
    if len(pending) > 0:
        pick = st.selectbox("Ch·ªçn id ƒë·ªÉ thao t√°c", options=["(ch·ªçn)"] + pending["id"].astype(str).tolist())
        if pick != "(ch·ªçn)":
            row = pending[pending["id"].astype(str)==pick].iloc[0]
            st.write(row.to_dict())
            if st.button("Approve"):
                pending.loc[pending["id"]==int(pick),"status"] = "approved"
                pending.to_csv(PENDING_PATH, index=False)
                st.success("ƒê√£ approve")
            if st.button("Reject"):
                pending.loc[pending["id"]==int(pick),"status"] = "rejected"
                pending.to_csv(PENDING_PATH, index=False)
                st.warning("ƒê√£ reject")
    st.markdown("---")
    st.subheader("Th√¥ng tin model")
    try:
        n_trees = model.named_steps['rf'].n_estimators
    except Exception:
        n_trees = "unknown"
    st.write(f"- RandomForest trees: {n_trees}")
    st.write(f"- Training sample size (app sample): {len(sample_df)}")
    st.write("- Anomaly detector: IsolationForest trained on features + residual")
    if FI_CSV.exists():
        st.dataframe(pd.read_csv(FI_CSV).head(30))
    else:
        st.info("feature_importances.csv not found in repo.")

# ----------------------
# Logs
# ----------------------
if page == "Nh·∫≠t k√Ω h·ªá th·ªëng":
    st.title("Nh·∫≠t k√Ω h·ªá th·ªëng ho·∫°t ƒë·ªông")
    if LOG_PATH.exists():
        logs = pd.read_csv(LOG_PATH)
        st.write(f"T·ªïng b·∫£n ghi: {len(logs)}")
        st.dataframe(logs.sort_values("timestamp", ascending=False).head(500))
        st.download_button("Export Logs CSV", data=logs.to_csv(index=False).encode('utf-8'), file_name="prediction_logs.csv", mime="text/csv")
    else:
        st.info("Ch∆∞a c√≥ logs n√†o")

# ----------------------
# Evaluation & Report (6 plots, professional, minimal)
# ----------------------
if page == "ƒê√°nh gi√° & B√°o c√°o k·∫øt qu·∫£":
    st.title("ƒê√°nh gi√° & B√°o c√°o k·∫øt qu·∫£")
    st.subheader("Sample data preview")
    st.dataframe(sample_df.head(200))

    # Prepare data safe names
    price_col = 'Gia_trieu' if 'Gia_trieu' in sample_df.columns else ('Gi√°' if 'Gi√°' in sample_df.columns else None)
    if price_col is None:
        st.error("Sample data kh√¥ng c√≥ c·ªôt gi√° (Gia_trieu / Gi√°).")
    else:
        df = sample_df.copy()
        df = df.dropna(subset=[price_col])
        # 1. Histogram (distribution)
        st.markdown("### Ph√¢n b·ªë gi√° t·ªïng th·ªÉ")
        fig1, ax1 = plt.subplots(figsize=(8,3))
        ax1.hist(df[price_col], bins=40)
        ax1.set_xlabel("Gi√° (Tri·ªáu)")
        ax1.set_ylabel("S·ªë tin")
        st.pyplot(fig1)

        # 2. Boxplot by brand (top 12 brands)
        st.markdown("### Ph√¢n b·ªë gi√° theo th∆∞∆°ng hi·ªáu (boxplot c√°c top brands)")
        top_brands = df['Th∆∞∆°ng hi·ªáu'].value_counts().head(12).index.tolist() if 'Th∆∞∆°ng hi·ªáu' in df.columns else []
        if top_brands:
            fig2, ax2 = plt.subplots(figsize=(10,4))
            data_to_plot = [df[df['Th∆∞∆°ng hi·ªáu'] == b][price_col].dropna() for b in top_brands]
            ax2.boxplot(data_to_plot, vert=False, labels=top_brands)
            ax2.set_xlabel("Gi√° (Tri·ªáu)")
            st.pyplot(fig2)
        else:
            st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu Th∆∞∆°ng hi·ªáu ƒë·ªÉ v·∫Ω boxplot.")

        # 3. Scatter Km vs Price with trendline
        if 'S·ªë Km ƒë√£ ƒëi' in df.columns:
            st.markdown("### M·ªëi t∆∞∆°ng quan: S·ªë Km vs Gi√°")
            x = pd.to_numeric(df['S·ªë Km ƒë√£ ƒëi'], errors='coerce')
            y = pd.to_numeric(df[price_col], errors='coerce')
            mask = (~x.isna()) & (~y.isna())
            if mask.sum() > 10:
                x1 = x[mask]
                y1 = y[mask]
                fig3, ax3 = plt.subplots(figsize=(8,4))
                ax3.scatter(x1, y1, alpha=0.4, s=10)
                # trendline (polyfit)
                m, b = np.polyfit(x1, y1, 1)
                xs = np.linspace(x1.min(), x1.max(), 100)
                ax3.plot(xs, m*xs + b, linewidth=2)
                ax3.set_xlabel("S·ªë Km ƒë√£ ƒëi")
                ax3.set_ylabel("Gi√° (Tri·ªáu)")
                st.pyplot(fig3)
            else:
                st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu Km ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì t∆∞∆°ng quan.")

        # 4. Feature importances (group-level)
        st.markdown("### Feature importances (top features)")
        if FI_CSV.exists():
            fi = pd.read_csv(FI_CSV)
            top = fi.head(20)
            fig4, ax4 = plt.subplots(figsize=(8,4))
            ax4.barh(top['feature'][::-1], top['importance'][::-1])
            ax4.set_xlabel("Importance")
            st.pyplot(fig4)
        else:
            st.info("Kh√¥ng t√¨m th·∫•y feature_importances.csv")

        # 5. Heatmap of numeric correlations
        st.markdown("### Heatmap t∆∞∆°ng quan c√°c bi·∫øn numeric")
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) >= 2:
            corr = df[numeric_cols].corr().fillna(0)
            fig5, ax5 = plt.subplots(figsize=(8,6))
            im = ax5.matshow(corr, aspect='auto')
            ax5.set_xticks(range(len(numeric_cols)))
            ax5.set_yticks(range(len(numeric_cols)))
            ax5.set_xticklabels(numeric_cols, rotation=90)
            ax5.set_yticklabels(numeric_cols)
            fig5.colorbar(im, ax=ax5)
            st.pyplot(fig5)
        else:
            st.info("Kh√¥ng ƒë·ªß bi·∫øn numeric ƒë·ªÉ v·∫Ω heatmap.")

        # 6. Anomaly score distribution (internal)
        st.markdown("### Ph√¢n b·ªë Anomaly Score (internal, cho admin)")
        if LOG_PATH.exists():
            logs = pd.read_csv(LOG_PATH)
            if 'anomaly_score' in logs.columns:
                fig6, ax6 = plt.subplots(figsize=(8,3))
                ax6.hist(logs['anomaly_score'].dropna(), bins=30)
                ax6.set_xlabel("Anomaly Score (internal)")
                st.pyplot(fig6)
            else:
                st.info("Ch∆∞a c√≥ tr∆∞·ªùng anomaly_score trong logs.")
        else:
            st.info("Ch∆∞a c√≥ logs ƒë·ªÉ v·∫Ω ph√¢n b·ªë anomaly score.")

# ----------------------
# Team Info
# ----------------------
if page == "Th√¥ng tin nh√≥m th·ª±c hi·ªán":
    st.title("Nh√≥m th·ª±c hi·ªán")
    st.markdown("- H·ªç t√™n HV: Nguyen Thai Binh")
    st.markdown("- Email: thaibinh782k1@gmail.com")
    st.markdown("- Repo: https://github.com/ThaiBinh78/ML07_Project")
    st.markdown("- Ng√†y report: 22/11/2025")

